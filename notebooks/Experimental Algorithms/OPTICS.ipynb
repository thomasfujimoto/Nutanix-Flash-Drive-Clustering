{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.cluster import OPTICS\n",
    "\n",
    "# Add the project root directory to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname('__file__'), '..')))\n",
    "from data_access.postgres_handler import PostgresHandler\n",
    "\n",
    "# Initialize the PostgresHandler\n",
    "handler = PostgresHandler(\n",
    "    database=\"nutanix\",\n",
    "    user=\"postgres\",\n",
    "    host=\"172.25.221.34\",\n",
    "    password=\"Senna\",\n",
    "    port=1433\n",
    ")\n",
    "\n",
    "handler.connect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    'concord_id', 'data_type', 'metric', 'queue_depth', 'num_jobs',\n",
    "    'blocksize', 'unit', 'min_measure', 'mean_measure', 'median_measure',\n",
    "    'max_measure', 'stddev_measure', 'device_type', 'family', 'vendor',\n",
    "    'model', 'firmware', 'capacity_GiB', 'operating_pci_speed_GTs',\n",
    "    'operating_pci_width', 'Linkrate_Gbs', 'name', 'reference', 'created'\n",
    "]\n",
    "\n",
    "df = handler.get_data(\"ssd_clean_data\", columns, limit=100000, encode=True)\n",
    "print(df.head())\n",
    "\n",
    "# Select only 60% of the dataset\n",
    "df = df.sample(frac=0.6, random_state=42)  # Randomly select 60% of the data\n",
    "print(df.shape)  # Verify the shape to ensure it's 60% of the original data\n",
    "\n",
    "print(df.columns)\n",
    "\n",
    "handler.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only numerical columns\n",
    "df_numerical = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_numerical), columns=df_numerical.columns)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_imputed), columns=df_imputed.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce to 10 dimensions using PCA\n",
    "pca = PCA(n_components=10, random_state=42)\n",
    "df_pca = pca.fit_transform(df_normalized)\n",
    "\n",
    "# Apply OPTICS again on reduced data\n",
    "optics_pca = OPTICS(min_samples=100, max_eps=1.0, xi=0.1)\n",
    "pca_cluster_labels = optics_pca.fit_predict(df_pca)\n",
    "\n",
    "# Add the cluster labels to the DataFrame\n",
    "df['PCA_OPTICS_Cluster'] = pca_cluster_labels\n",
    "print(df['PCA_OPTICS_Cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OPTICS with parameters\n",
    "#optics = OPTICS(min_samples=50, max_eps=0.5, cluster_method='xi')\n",
    "optics = OPTICS(min_samples=300, max_eps=1.0, xi=0.1)\n",
    "\n",
    "# Fit the model on the normalized data\n",
    "cluster_labels = optics.fit_predict(df_normalized)\n",
    "\n",
    "# Add the cluster labels back to the original DataFrame\n",
    "df['Cluster'] = cluster_labels\n",
    "\n",
    "print(df['Cluster'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Apply t-SNE to reduce dimensions to 2\n",
    "tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, random_state=42)\n",
    "df_tsne = pd.DataFrame(tsne.fit_transform(df_normalized), columns=['t-SNE1', 't-SNE2'])\n",
    "\n",
    "# Add the cluster labels to the t-SNE DataFrame\n",
    "df_tsne['Cluster'] = df['Cluster']\n",
    "\n",
    "# Plot t-SNE with clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.scatterplot(data=df_tsne, x='t-SNE1', y='t-SNE2', hue='Cluster', palette='tab10', s=100, alpha=0.7)\n",
    "plt.title('t-SNE of Data Points (OPTICS Clustering)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cluster_summary = df.groupby('Cluster')[numeric_columns].mean()\n",
    "\n",
    "print(cluster_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a reachability plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "space = np.arange(len(df_normalized))\n",
    "reachability = optics.reachability_[optics.ordering_]\n",
    "labels = optics.labels_[optics.ordering_]\n",
    "\n",
    "plt.plot(space, reachability, 'k-', alpha=0.7)\n",
    "for class_member in np.unique(labels):\n",
    "    if class_member != -1:\n",
    "        mask = (labels == class_member)\n",
    "        plt.plot(space[mask], reachability[mask], marker='o', linestyle='-', alpha=0.7)\n",
    "\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Reachability Distance')\n",
    "plt.title('Reachability Plot')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Step 1: Print unique values in 'data_type' and 'metric' to determine encoding mappings\n",
    "print(\"Unique values in 'data_type':\", df['data_type'].unique())\n",
    "print(\"Unique values in 'metric':\", df['metric'].unique())\n",
    "\n",
    "# Define the Data Types and Encoding for Each Feature based on printed mappings\n",
    "data_types = [\n",
    "    {\"name\": \"Random Read Latency\", \"type\": 0, \"metric\": 2},\n",
    "    {\"name\": \"Random Write Latency\", \"type\": 1, \"metric\": 2},\n",
    "    {\"name\": \"Random Read\", \"type\": 0, \"metric\": None},\n",
    "    {\"name\": \"Random Write\", \"type\": 1, \"metric\": None},\n",
    "    {\"name\": \"Sequential Write\", \"type\": 3, \"metric\": None},\n",
    "    {\"name\": \"Sequential Read\", \"type\": 2, \"metric\": None}\n",
    "]\n",
    "\n",
    "# OPTICS clustering parameters\n",
    "min_samples = 100\n",
    "max_eps = 1.0\n",
    "xi = 0.1\n",
    "\n",
    "# Loop through each feature type and apply OPTICS clustering\n",
    "for item in data_types:\n",
    "    name = item[\"name\"]\n",
    "    specific_type = item[\"type\"]\n",
    "    latency_metric = item[\"metric\"]\n",
    "    \n",
    "    print(f\"Processing {name}...\")\n",
    "\n",
    "    # Step 2: Filter the DataFrame for the specific encoded data type\n",
    "    df_specific = df[df['data_type'] == specific_type].copy()\n",
    "    \n",
    "    # Step 3: If a latency metric is specified, apply the additional filter\n",
    "    if latency_metric is not None:\n",
    "        df_specific = df_specific[df_specific['metric'] == latency_metric]\n",
    "\n",
    "    # Check if df_specific is empty\n",
    "    if df_specific.empty:\n",
    "        print(f\"No data found for data_type = '{specific_type}' with metric = '{latency_metric}'\")\n",
    "        continue\n",
    "    else:\n",
    "        print(f\"Data found for {name}: {df_specific.shape[0]} rows\")\n",
    "\n",
    "    # Step 4: Select numerical columns\n",
    "    df_numerical = df_specific.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "    # Step 5: Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    df_imputed = pd.DataFrame(imputer.fit_transform(df_numerical), columns=df_numerical.columns)\n",
    "    \n",
    "    # Step 6: Normalize data\n",
    "    scaler = MinMaxScaler()\n",
    "    df_normalized = pd.DataFrame(scaler.fit_transform(df_imputed), columns=df_imputed.columns)\n",
    "    \n",
    "    # Step 7: Apply OPTICS clustering\n",
    "    optics = OPTICS(min_samples=min_samples, max_eps=max_eps, xi=xi)\n",
    "    cluster_labels = optics.fit_predict(df_normalized)\n",
    "\n",
    "    # Add the cluster labels to the original DataFrame for visualization\n",
    "    df_specific['OPTICS_Cluster'] = cluster_labels\n",
    "\n",
    "    # Step 8: Calculate the silhouette score (exclude noise points labeled as -1)\n",
    "    non_noise_points = df_normalized[cluster_labels != -1]\n",
    "    non_noise_labels = cluster_labels[cluster_labels != -1]\n",
    "\n",
    "    if len(set(non_noise_labels)) > 1:  # Ensure there's more than one cluster\n",
    "        score = silhouette_score(non_noise_points, non_noise_labels)\n",
    "        print(f\"Silhouette Score for {name} with min_samples={min_samples}: {score:.4f}\")\n",
    "    else:\n",
    "        print(f\"Silhouette Score for {name} with min_samples={min_samples}: Not applicable (only one cluster or no clusters)\")\n",
    "\n",
    "    # Step 9: Visualize with t-SNE\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(df_normalized)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.scatterplot(x=tsne_results[:, 0], y=tsne_results[:, 1], hue=cluster_labels, palette='tab10', s=10)\n",
    "    plt.title(f't-SNE Visualization of OPTICS Clusters for {name}')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.legend(title='Cluster', loc='best')\n",
    "    plt.show()\n",
    "\n",
    "    # Display cluster counts for each category\n",
    "    print(df_specific['OPTICS_Cluster'].value_counts())\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
