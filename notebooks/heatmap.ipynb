{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install psycopg2-binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Connect to the database\n",
    "conn = psycopg2.connect(database=\"nutanix\", \n",
    "                        user=\"postgres\", \n",
    "                        host='172.25.221.34',\n",
    "                        password=\"Senna\",\n",
    "                        port=1433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Create a cursor\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # Execute a query to count the total number of rows in the ssd_perf_data table\n",
    "    cur.execute(\"SELECT COUNT(*) FROM ssd_perf_data;\")\n",
    "    total_rows = cur.fetchone()[0]  # Fetch the count result\n",
    "\n",
    "    # Print the total number of rows\n",
    "    print(f\"Total number of rows in ssd_perf_data: {total_rows}\")\n",
    "\n",
    "    # Execute a query to select the first 10 rows from the ssd_perf_data table\n",
    "    cur.execute(\"SELECT * FROM ssd_perf_data LIMIT 200000;\")\n",
    "    rows = cur.fetchall()  # Fetch all results\n",
    "\n",
    "    # Print the number of rows returned by the LIMIT query\n",
    "    # print(f\"Number of rows returned: {len(rows)}\")\n",
    "\n",
    "    # Print the contents of the table\n",
    "    # for row in rows:\n",
    "    #     print(row)  # Print each row\n",
    "        \n",
    "    # Store Each Values into a DF \n",
    "    # Get column names from cursor description\n",
    "    column_names = [desc[0] for desc in cur.description]\n",
    "\n",
    "    # Pass the result into a pandas DataFrame\n",
    "    df = pd.DataFrame(rows, columns=column_names)\n",
    "    \n",
    "    # Print the Data Frame \n",
    "    print(df)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "finally:\n",
    "    # Close the cursor and connection\n",
    "    if cur:\n",
    "        cur.close()\n",
    "    if conn:\n",
    "        conn.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering (Messing Around w/ GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of 2D Plot Clustering (REALLY BAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming `df` is your DataFrame with SSD performance data\n",
    "# Select numeric features and normalize\n",
    "features = df.select_dtypes(include=['float64', 'int64']).dropna()\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(features)\n",
    "\n",
    "# Apply t-SNE for dimensionality reduction to 2 components\n",
    "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "features_tsne = tsne.fit_transform(features_normalized)\n",
    "\n",
    "# Assuming you've already clustered data and added a 'tier' column\n",
    "k = 4  # Assuming you have k=4 clusters from K-Means\n",
    "df['tier'] = KMeans(n_clusters=k, random_state=42).fit_predict(features_normalized)\n",
    "\n",
    "# Plot the t-SNE clusters\n",
    "plt.scatter(features_tsne[:, 0], features_tsne[:, 1], c=df['tier'], cmap='viridis')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.title('SSD Performance Tiers (t-SNE Visualization)')\n",
    "plt.colorbar(label='Cluster Label')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of Heat Map with no Categorical Data (KINDA BAD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assume `df` is your DataFrame containing the SSD performance data\n",
    "# Select numeric features and normalize them\n",
    "numeric_df = df.select_dtypes(include=['float64', 'int64']).dropna()\n",
    "scaler = StandardScaler()\n",
    "features_normalized = scaler.fit_transform(numeric_df)\n",
    "\n",
    "# Lower blocksize Dominance \n",
    "df[numeric_df] = df[numeric_df].apply(lambda x: np.log1p(x))\n",
    "\n",
    "# Apply K-Means clustering\n",
    "k = 10  # Number of clusters/tier levels\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['tier'] = kmeans.fit_predict(features_normalized)\n",
    "\n",
    "# Select only numeric columns for aggregation\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cluster_summary = df.groupby('tier')[numeric_columns].mean()\n",
    "\n",
    "# Create a heatmap of the average metrics per cluster\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(cluster_summary.T, cmap='viridis', annot=True, fmt=\".2f\")\n",
    "plt.title('Cluster Feature Averages Heatmap')\n",
    "plt.xlabel('Cluster (Tier)')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
